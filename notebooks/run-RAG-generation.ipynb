{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f430a9cf-6456-4273-8ff6-5fcdc71f1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "import torch\n",
    "import os\n",
    "from utils import match_dates_based_on_precision, parse_date\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba709e5-7657-4a2c-9158-d02a432afc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir='/data/amandeep/huggingface_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "os.environ['XDG_CACHE_HOME'] = cache_dir\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9665685-66ea-4678-ac06-49e1028d3841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb51ce6-8308-40b9-bceb-2bbe62dd06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Using custom data configuration psgs_w100.nq.no_index-dummy=False,with_index=False\n",
      "Reusing dataset wiki_dpr (/data/amandeep/huggingface_cache/huggingface/datasets/wiki_dpr/psgs_w100.nq.no_index-dummy=False,with_index=False/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54)\n",
      "Using custom data configuration psgs_w100.nq.exact-2ac68f9d64417cf4\n",
      "Reusing dataset wiki_dpr (/data/amandeep/huggingface_cache/huggingface/datasets/wiki_dpr/psgs_w100.nq.exact-2ac68f9d64417cf4/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54)\n"
     ]
    }
   ],
   "source": [
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", \n",
    "                                         index_name=\"exact\", \n",
    "                                         use_dummy_dataset=False, \n",
    "                                         cache_dir='/data/amandeep/huggingface_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadb377a-2a67-49df-ba51-1d3bc3036df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagTokenForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagTokenForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagTokenForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RagTokenForGeneration were not initialized from the model checkpoint at facebook/rag-token-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec85f8-b5d6-41c1-9c44-3a8dcda2962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"When did Barack Obama get married?\", \n",
    "             \"When did Joe Biden get married?\", \n",
    "             \"When did Joe Biden and Neilia get married?\",\n",
    "             \"When did Sachin Tendulkar get married?\",\n",
    "            \"when did Kailin Curran marry Keanu?\",\n",
    "            \"when did Guillaume Canet marry Diane?\",\n",
    "            \"when did Sujarinee Vivacharawongse marry Vajiralongkorn I of?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edba4b3-3b81-40c1-ae12-24537c255405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag(question):\n",
    "    input_dict = tokenizer.prepare_seq2seq_batch(question, return_tensors=\"pt\")\n",
    "    # generated = model.generate(input_ids=input_dict[\"input_ids\"], n_docs=100) \n",
    "    generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "    return tokenizer.batch_decode(generated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047dd6a6-70e1-46e0-94aa-723e1cbd5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fe97e-8195-473e-859d-dd4e4d48bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> List[str]:\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "    docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "    doc_scores = torch.bmm(\n",
    "        question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    "    ).squeeze(1)\n",
    "\n",
    "    generated = model.generate(\n",
    "        context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "        context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "        doc_scores=doc_scores,\n",
    "    )\n",
    "    generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "    return generated_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c070455c-115d-4ca6-a022-684f6af7068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_f = open('../data/dpr-post-process-unified-qa-matched.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58641b3f-73cf-4b4a-866a-626e2599cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answers = []\n",
    "c = 1\n",
    "for line in questions_f:\n",
    "    if c % 1000 == 0:\n",
    "        print(c)\n",
    "    c += 1 \n",
    "    j = json.loads(line.strip())\n",
    "    rag_answer = run_rag(j['q'])\n",
    "    j['rag_answer'] = {'raw_answer': rag_answer}\n",
    "    rag_answers.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7cc93-d817-4dbc-8b08-a97e19aa1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answers[7706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528e2d66-8f8d-4af9-9da3-f703734dfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_to_p_dict = json.load(open('../data/questions_o_precision_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72601620-5009-46ec-aa9e-a702e9ee9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ra in rag_answers:\n",
    "    rag_raw_dates = ra['rag_answer']['raw_answer']\n",
    "    ra_matched = False\n",
    "    for rrd in rag_raw_dates:\n",
    "        parsed_dates = parse_date(rrd, nlp)\n",
    "        for pd in parsed_dates:\n",
    "            ra_matched, prov = match_dates_based_on_precision(ra['a'], q_to_p_dict[ra['q']], pd)\n",
    "            if ra_matched:\n",
    "                ra['rag_answer']['parsed_date'] = pd \n",
    "                break\n",
    "        ra['rag_answer']['matched'] = ra_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfd41e-0622-49d1-b44b-e9460a77ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answers[7706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd06f6e-8543-42bc-815a-293d7cddb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "matched_rag_answers = []\n",
    "for ra in rag_answers:\n",
    "    rag_a = ra['rag_answer']\n",
    "    if rag_a['matched']:\n",
    "        c += 1\n",
    "        matched_rag_answers.append(ra)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb1e85-296a-4f14-baa3-aaf68827d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_rag_answers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e0c3f-1995-42fc-ab31-938f769b20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = open('../data/dpr-post-process-unified-qa-and-rag-matched.jl', 'w')\n",
    "for mra in matched_rag_answers:\n",
    "    o.write(json.dumps(mra))\n",
    "    o.write('\\n')\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0feab-7b78-475c-9ffc-88a5987e68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_with_context(question, dpr_answer):\n",
    "    input_dict = tokenizer.prepare_seq2seq_batch(question, tgt_texts = dpr_answer, return_tensors=\"pt\")\n",
    "    generated = model.generate(input_ids=input_dict[\"input_ids\"], \n",
    "                               attention_mask=input_dict['attention_mask'],\n",
    "                              context_input_ids=input_dict['labels'], n_docs=1) \n",
    "    return tokenizer.batch_decode(generated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c6a56-ebba-469a-895b-d3ea5948aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_d = run_rag_with_context('when did Prince Christian of Hanover marry Alessandra de?',\n",
    "                           'Following his father\\'s marriage to Princess Caroline, Christian and his family moved to Fontainebleau, Paris, France. Christian later continued with his education at Malvern College. In 2004, Christian\\'s father signed over to his sons the German property of the House of Hanover, including Marienburg Castle. The two brothers hired a Sotheby\\'s team to auction off some of the castle\\'s content in order to save its finances. On 24 November 2017, Christian married Peruvian lawyer Alessandra de Osma Foy (born 1988), daughter of Felipe de Osma Berckemeyer and Elizabeth Foy VÃ¡squez, during a civil service at the Chelsea and Westminster register')\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51df411b-3c7e-441b-b168-16fca49a23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_token_generate_batch(questions, tokenizer, retriever, model, torch_device='cpu'):\n",
    "    \n",
    "    input_dict = tokenizer(\n",
    "        questions,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = input_dict.input_ids.to(torch_device)\n",
    "    attention_mask = input_dict.attention_mask.to(torch_device)\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        n_docs=100\n",
    "    )\n",
    "    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f8fef3-1eb4-41b6-8fc6-b74b21badade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/transformers/generation_utils.py:2129: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' 24 august 1971']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_token_generate_batch(['when did Sachin Tendulkar marry Anjali?'], tokenizer, retriever, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd3bc0e-1d87-4076-82d4-1ca0c447f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_f = open('../data/dpr-post-process-unified-qa-matched.jl')\n",
    "questions = []\n",
    "for line in questions_f:\n",
    "    questions.append(json.loads(line.strip()))\n",
    "questions_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ce0d09-ccea-4ff6-b176-307796b78999",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_o = open('../data/dpr-post-process-unified-qa-plus-rag-k-100.jl', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db8c57-55ee-4d65-97f1-586e20503cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/transformers/generation_utils.py:2129: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for q in questions:\n",
    "    if c%1000 == 0:\n",
    "        print(c)\n",
    "    c += 1\n",
    "    q['rag_answer'] = rag_token_generate_batch(q['q'], tokenizer, retriever, model)\n",
    "    rag_o.write(json.dumps(q))\n",
    "    rag_o.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42a1f82-0946-4abc-a470-92ade99b63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63f905-d239-4170-8548-e2de357e5a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
