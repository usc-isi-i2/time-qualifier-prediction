{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04175eb4-0050-4522-ae45-9e318cdcb5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import parse_date, match_dates_based_on_precision, month_dict, extract_node1_node2, create_other_dates, format_dates, precision_dict\n",
    "import spacy\n",
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e53e663-2ac9-4d1a-bde4-b73cd441bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d92fe98-aa92-42c7-83c8-7cde08e0d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/dpr-post-process-unified-qa-matched.jl'\n",
    "annotated_file = '../data/questions-for-annotation-annotated.csv'\n",
    "evaluation_input_file = '../data/annotated-questions-for-evaluation.tsv'\n",
    "evaluation_output_file = '../data/eval_output/output.tsv-95000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ea3258-8ffe-4fc0-a8ae-7c4732462629",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.read_csv(annotated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5d623e-9c0c-40f3-b84e-d1c498a89906",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_questions = set(annotated_df['question'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8752fe06-1348-416d-8aa8-e69f73530508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "502bec49-69ef-4d05-9e0f-d662b91d3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter_questions(input_file):\n",
    "    all_questions = list()\n",
    "    with open(input_file) as f:\n",
    "        for line in f:\n",
    "            j = json.loads(line.strip())\n",
    "            answer = j['a']\n",
    "            question = j['q']\n",
    "            if answer < '2020-01-01':\n",
    "                if question not in annotated_questions:\n",
    "                    all_questions.append(j)\n",
    "\n",
    "    questions_with_spacy_matched = []\n",
    "    for aq in all_questions:\n",
    "        dpr_answers = aq['matched_dpr_answers']\n",
    "        for da in dpr_answers:\n",
    "            if da['matched']:\n",
    "                aq['matched_dpr_answer'] = da['dpr_answer']\n",
    "                aq.pop('matched_dpr_answers')\n",
    "                questions_with_spacy_matched.append(aq)\n",
    "                break\n",
    "    return questions_with_spacy_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fbe6cff-e3b0-42d1-927f-db6dac1ef4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_with_spacy_matched = load_filter_questions(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5697b4b-2f39-4252-a64b-8185c5042163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13254"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_with_spacy_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c63c274-8fbd-4d0e-ab03-7a52ad47cedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 'when did Frederick Hervey, 8th Marquess of Bristol marry Meredith?',\n",
       " 'a': '2018-05-11',\n",
       " 'n1': 'Q5498020',\n",
       " 'n2': 'Q76353883',\n",
       " 'n1_label': 'Frederick Hervey, 8th Marquess of Bristol',\n",
       " 'n2_label': 'Meredith Dunn',\n",
       " 'url': 'http://en.wikipedia.org/wiki/Frederick_Hervey,_8th_Marquess_of_Bristol',\n",
       " 'precision': '11',\n",
       " 'spacy_matched': True,\n",
       " 'uqa_matched': True,\n",
       " 'matched_dpr_answer': '\"Frederick Hervey, 8th Marquess of Bristol\"\\nthe National Trust for not reselling what would have been the remaining term of that leasehold to him, arguing that the 7th Marquess could only sell his own life interest, not that of his descendants. This was disputed by the National Trust who have since converted the East Wing into a hotel. However, in 2009 Sir Simon Jenkins, the National Trust\\'s new chairman, stated, \"\"I think it is in our interest for the Marquesses of Bristol to be living there.\"\" On 11 May 2018 Lord Bristol married Meredith Dunn, an American art consultant, in a Roman Catholic wedding at the'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_spacy_matched[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb98b8f5-a552-4117-b7a4-147883973abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_100_questions_for_manual_annotation():\n",
    "    random_questions = random.choices(questions_with_spacy_matched, k=100)\n",
    "    print(len(random_questions))\n",
    "    random_df = pd.DataFrame(random_questions)\n",
    "    random_df.rename(columns={'q': 'question', \n",
    "                              'a': 'answer', \n",
    "                              'matched_dpr_answer': 'dpr_answer_a'}, inplace=True)\n",
    "    random_df['dpr_answer'] = random_df['dpr_answer_a'].map(lambda x: x.split('\\n')[1])\n",
    "    random_df['precision'] = random_df['precision'].map(lambda x: precision_dict.get(x))\n",
    "    random_df.drop(columns=['n1', 'n2', 'n1_label', 'n2_label','url', 'spacy_matched', 'uqa_matched', 'dpr_answer_a'], inplace=True)\n",
    "    r = pd.concat([annotated_df, random_df]).fillna(\"\")\n",
    "    r.to_csv(annotated_file_v2, index=False)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90614cff-7ed0-4745-898e-58ffdd08aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "pick_100_questions_for_manual_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a2c2cd-50ce-4e59-953b-20f2072621a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spacy_matched_answers(list_questions):\n",
    "    c = 1\n",
    "    for q in list_questions:\n",
    "        if c%1000 == 0:\n",
    "            print(c)\n",
    "        c += 1\n",
    "        precision = q['precision']\n",
    "        spacy_dates = parse_date(q['matched_dpr_answer'], nlp, 'year') # precision year because we want to extract any dates\n",
    "        for sd in spacy_dates:\n",
    "            matched, prov  = match_dates_based_on_precision(q['a'], 'year', sd)\n",
    "            if matched:\n",
    "                q['spacy_matched_date'] =  sd['orig_date']\n",
    "                break\n",
    "    return list_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59679d44-2f83-44bd-a488-228739776fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/amandeep/miniconda3/envs/python3/lib/python3.9/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "questions_with_spacy_matched_2 = add_spacy_matched_answers(questions_with_spacy_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "118e64b2-8100-4671-b81b-c7b4f25873e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 'when did Aaron Paul marry Lauren?',\n",
       " 'a': '2013-05-26',\n",
       " 'n1': 'Q302491',\n",
       " 'n2': 'Q40459846',\n",
       " 'n1_label': 'Aaron Paul',\n",
       " 'n2_label': 'Lauren Parsekian',\n",
       " 'url': 'http://en.wikipedia.org/wiki/Aaron_Paul',\n",
       " 'precision': '11',\n",
       " 'spacy_matched': True,\n",
       " 'uqa_matched': True,\n",
       " 'matched_dpr_answer': '\"Aaron Paul\"\\nParis on January 1, 2012. The two met at Coachella in Indio, California. They were married on May 26, 2013, in a 1920s Parisian carnival-themed wedding, in Malibu, California; music was provided by Foster the People and John Mayer. Paul emailed the song \"\"Beauty\"\" by The Shivers to everyone on the guest list and asked them to learn the words so they could sing along during the ceremony. In September 2017, Paul announced that he and Parsekian were expecting their first child. Their daughter, Story, was born in February 2018. To commemorate the final episode of \"\"Breaking Bad\"\", Paul and',\n",
       " 'spacy_matched_date': 'May 26, 2013'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_spacy_matched_2[560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5dd3677c-ee5b-47f3-9b1d-ec459a467e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(questions_with_spacy_matched_2, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f8b4201-875c-45c9-934b-ff91be6f3e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9865 3289\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88f7b907-0bec-4994-a2fe-5a5b51f2323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unified_qa_model_input_files(list_questions, bart_file_name, t5_file_name):\n",
    "    bart_o = open(bart_file_name, 'w')\n",
    "    t5_o = open(t5_file_name, 'w')\n",
    "    actual_answer = 0\n",
    "    no_answer = 0\n",
    "    ojson = []\n",
    "    for q in list_questions:\n",
    "        question = q['q']\n",
    "        answer = q.get('spacy_matched_date', None)\n",
    "        if answer is None:\n",
    "            answer = '<no answer>'\n",
    "            no_answer += 1\n",
    "        dpr_a  = q['matched_dpr_answer'].split('\\n')[1]\n",
    "        w_dpr_a = ''\n",
    "        n2_trunc = ''\n",
    "        try:\n",
    "            w_dpr_a = q['wrong_matched_dpr_answer'].split('\\n')[1]\n",
    "        except:\n",
    "            w_dpr_a = q['wrong_matched_dpr_answer']\n",
    "        w_d_dpr_a = q.get('wrong_date_dpr_answer', None)\n",
    "        n2_trunc = q['n2_label_trunc']\n",
    "        \n",
    "        \n",
    "        if n2_trunc in dpr_a:\n",
    "            bart_o.write(f\"{question}\\\\n{dpr_a}\\t{answer}\\n\")\n",
    "            ojson.append({'input': f\"{question}\\n{dpr_a}\", 'output':answer, 'precision': q['precision']})\n",
    "            actual_answer += 1\n",
    "        else:\n",
    "            bart_o.write(f\"{question}\\\\n{dpr_a}\\t<no answer>\\n\")\n",
    "            ojson.append({'input': f\"{question}\\n{dpr_a}\", 'output':\"<no answer>\", 'precision': q['precision']})\n",
    "            no_answer += 1\n",
    "\n",
    "        bart_o.write(f\"{question}\\\\n{w_dpr_a}\\t<no answer>\\n\")\n",
    "        ojson.append({'input': f\"{question}\\n{w_dpr_a}\", 'output':\"<no answer>\", 'precision': q['precision']})\n",
    "        no_answer += 1\n",
    "        if w_d_dpr_a is not None:\n",
    "            bart_o.write(f\"{question}\\\\n{w_d_dpr_a}\\t<no answer>\\n\")\n",
    "        \n",
    "    print(actual_answer, no_answer)\n",
    "    t5_o.write(json.dumps(ojson))\n",
    "    bart_o.close()\n",
    "    t5_o.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76fa6a-948b-4fff-80b1-50c929d4b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_unified_qa_model_input_files(train, \n",
    "                                    '../data/unified_qa_input/v2/bart_train.tsv',\n",
    "                                   '../data/unified_qa_input/v2/t5_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb158c-d52e-438e-9ac4-7cb3e70ba074",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_unified_qa_model_input_files(test, '../data/unified_qa_input/v2/bart_test.tsv',\n",
    "                                   '../data/unified_qa_input/v2/f5_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96c38a-c59c-4b66-bb93-05cdb1b6e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_for_evaluation(annotated_file, evaluation_input_file):\n",
    "    df = pd.read_csv(annotated_file)\n",
    "    o = open(evaluation_input_file, 'w')\n",
    "    for question, para in list(zip(df['question'], df['dpr_answer'])):\n",
    "        fstring = f\"{question}\\\\n{para}\\n\"\n",
    "        o.write(fstring)\n",
    "    o.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c8617-521a-4256-878a-443a1b888d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_input_for_evaluation(annotated_file, evaluation_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a78c3e1c-0fa6-49c1-b757-b68ad37f6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_names_overlap(name1: str, name2: str):\n",
    "    name_parts = name2.split()\n",
    "    for name_part in name_parts:\n",
    "        if name_part in name1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f912de2a-d4f7-4efe-b5cd-38c99b1fcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(question_set, node_set, create_wrong_date=False):\n",
    "    c = 0\n",
    "    new_set = []\n",
    "    for q in question_set:\n",
    "        c += 1\n",
    "        if c%1000 == 0:\n",
    "            print(c)\n",
    "        node1, node2 = extract_node1_node2(q['q'])\n",
    "        if create_wrong_date:\n",
    "            precision = str(q['precision'])\n",
    "            requires = ['year', 'month'] if precision in ('10','11') else ['year']\n",
    "            parsed_dates =  parse_date(q['matched_dpr_answer'], nlp)\n",
    "            wrong_date_dpr_answer = ''\n",
    "            for pd in parsed_dates:\n",
    "                matched, p = match_dates_based_on_precision(q['a'], precision, pd)\n",
    "                if matched:\n",
    "                    new_date = format_dates(create_other_dates(pd['date'], 1, based_on=precision)[0], precision)\n",
    "                    # print(pd['date'], q['a'], new_date, precision)\n",
    "                    wrong_date_dpr_answer = q['matched_dpr_answer'].replace(pd['orig_date'], new_date)\n",
    "                    # print(wrong_date_dpr_answer)\n",
    "                    break\n",
    "            if wrong_date_dpr_answer != '':\n",
    "                q['wrong_date_dpr_answer'] = wrong_date_dpr_answer\n",
    "        q['n2_label_trunc'] = node2\n",
    "        newn2 = ''\n",
    "        spacy_docs = nlp(q['matched_dpr_answer'])\n",
    "        spacy_persons = [x.text for x in spacy_docs.ents if x.label_ == 'PERSON']\n",
    "\n",
    "        while True:\n",
    "            newn2 = random.choice(node_set)\n",
    "            # if newn2 != node1 and newn2 != node2:\n",
    "            if not check_names_overlap(node1, newn2) and not check_names_overlap(node2, newn2):\n",
    "                break\n",
    " \n",
    "        found_node2 = False\n",
    "        for sp in spacy_persons:\n",
    "            if node2 in sp:\n",
    "                q['wrong_matched_dpr_answer'] = q['matched_dpr_answer'].replace(sp, newn2)\n",
    "                found_node2 = True\n",
    "                break\n",
    "        if not found_node2:\n",
    "            q['wrong_matched_dpr_answer'] = q['matched_dpr_answer'].replace(node2, newn2)\n",
    "            \n",
    "        new_set.append(q)\n",
    "    return new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d40ae01-f90f-4fb2-847a-4c2152fdbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_no_answer_training_dataset(train_set, test_set):\n",
    "    \n",
    "    train_nodes = set()\n",
    "    test_nodes  = set()\n",
    "    for question in train_set:\n",
    "        node1, node2 = extract_node1_node2(question['q'])\n",
    "        train_nodes.add(node2)\n",
    "    for question in test_set:\n",
    "        node1, node2 = extract_node1_node2(question['q'])\n",
    "        test_nodes.add(node2)\n",
    "\n",
    "    train_nodes = list(train_nodes)\n",
    "    test_nodes = list(test_nodes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_train_set = helper(train_set, train_nodes)\n",
    "    new_test_set = helper(test_set, test_nodes)\n",
    "\n",
    "    assert len(train_set) == len(new_train_set)\n",
    "    assert len(test_set) == len(new_test_set)\n",
    "    return new_train_set, new_test_set\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2284f7a-171b-4bd6-aee4-2dd0178b4bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "new_train, new_test = create_no_answer_training_dataset(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3994785-7a7c-4068-ab17-a3bd46637549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7620 12110\n"
     ]
    }
   ],
   "source": [
    "create_unified_qa_model_input_files(new_train, '../data/unified_qa_input/v9/bart_train.tsv', '../data/unified_qa_input/v9/t5_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2800aa14-df5b-41a8-b598-8d6f95ef99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582 3997\n"
     ]
    }
   ],
   "source": [
    "create_unified_qa_model_input_files(new_test, '../data/unified_qa_input/v9/bart_test.tsv', '../data/unified_qa_input/v9/t5_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "367e83e9-a19b-4315-995c-0fc756ba15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_unified_qa_model_input_files(train, '../data/unified_qa_input/v7/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81325d5e-26b1-43b5-b710-2e46def977c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_unified_qa_model_input_files(test, '../data/unified_qa_input/v7/test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cdba1-a499-4b5d-878b-916906157f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
